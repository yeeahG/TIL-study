{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05b7621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(\"/data/retail-data/all/*.csv\")\\\n",
    "  .coalesce(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "946a8726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd39b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InvoiceNo',\n",
       " 'StockCode',\n",
       " 'Description',\n",
       " 'Quantity',\n",
       " 'InvoiceDate',\n",
       " 'UnitPrice',\n",
       " 'CustomerID',\n",
       " 'Country']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6f4186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|count(StockCode)|\n",
      "+----------------+\n",
      "|          541909|\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 컬럼 count \n",
    "from pyspark.sql.functions import count\n",
    "df.select(count(\"StockCode\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7f6b0",
   "metadata": {},
   "source": [
    "## countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd7584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 3) / 3]\r",
      "\r",
      "[Stage 5:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|                     4070|\n",
      "+-------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# countDistinct\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df.select(countDistinct(\"StockCode\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937144e",
   "metadata": {},
   "source": [
    "## approx_count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e753d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            3364|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 근사치 확인하기\n",
    "# 사용 용도 -> 데이터셋이 크면... 전체 스캔하는데 시간 오래걸리기 때문에 \n",
    "# 대략적인 크기 파악(속도... )\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "df.select(approx_count_distinct(\"StockCode\",0.1) ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e724a8d",
   "metadata": {},
   "source": [
    "## first, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057987c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+\n",
      "|first(invoiceno)|last(StockCode)|\n",
      "+----------------+---------------+\n",
      "|          571103|         85099C|\n",
      "+----------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 컬럼별 first, last 데이터 확인 \n",
    "from pyspark.sql.functions import first, last\n",
    "df.select(first('invoiceno'), last('StockCode')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90be81ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(InvoiceNo,StringType,true),StructField(StockCode,StringType,true),StructField(Description,StringType,true),StructField(Quantity,IntegerType,true),StructField(InvoiceDate,StringType,true),StructField(UnitPrice,DoubleType,true),StructField(CustomerID,IntegerType,true),StructField(Country,StringType,true)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a4aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|first(stockcode)|\n",
      "+----------------+\n",
      "|          85123A|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first, last\n",
    "df.select(first('stockcode')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "885e5d26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m first, last\n\u001b[0;32m----> 2\u001b[0m df\u001b[38;5;241m.\u001b[39msort(\u001b[43mcol\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStockCode\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc())\u001b[38;5;241m.\u001b[39mselect(first(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStockCode\u001b[39m\u001b[38;5;124m'\u001b[39m), last(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStockCode\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first, last\n",
    "df.sort(col('StockCode').desc()).select(first('StockCode'), last('StockCode')).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73275bd4",
   "metadata": {},
   "source": [
    "## min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fc3e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84504975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|min(Quantity)|max(Quantity)|\n",
      "+-------------+-------------+\n",
      "|       -80995|        80995|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min(\"Quantity\"), max(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed0aed",
   "metadata": {},
   "source": [
    "## sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e96b93b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|sum(Quantity)|\n",
      "+-------------+\n",
      "|      5176450|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "df.select(sum('Quantity')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1889af",
   "metadata": {},
   "source": [
    "## sumDistinct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec3b3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|sum(DISTINCT Quantity)|\n",
      "+----------------------+\n",
      "|                 29310|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum_distinct \n",
    "df.select(sum_distinct ('Quantity')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2199500",
   "metadata": {},
   "source": [
    "## avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c9cd883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+----------------+----------------+\n",
      "|(total_purchases / total_transactions)|   avg_purchases|  mean_purchases|\n",
      "+--------------------------------------+----------------+----------------+\n",
      "|                      9.55224954743324|9.55224954743324|9.55224954743324|\n",
      "+--------------------------------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, avg, expr\n",
    "\n",
    "df.select(\n",
    "    count(\"Quantity\").alias(\"total_transactions\"),\n",
    "    sum(\"Quantity\").alias(\"total_purchases\"),\n",
    "    avg(\"Quantity\").alias(\"avg_purchases\"),\n",
    "    expr(\"mean(Quantity)\").alias(\"mean_purchases\"))\\\n",
    "  .selectExpr(\n",
    "    \"total_purchases/total_transactions\",\n",
    "    \"avg_purchases\",\n",
    "    \"mean_purchases\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79271e4",
   "metadata": {},
   "source": [
    "## 분산, 표준편차 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "179b0986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+---------------------+\n",
      "|var_pop(Quantity)|var_samp(Quantity)|stddev_pop(Quantity)|stddev_samp(Quantity)|\n",
      "+-----------------+------------------+--------------------+---------------------+\n",
      "|  47559.303646609| 47559.39140929869|  218.08095663447781|   218.08115785023404|\n",
      "+-----------------+------------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import var_pop, stddev_pop\n",
    "from pyspark.sql.functions import var_samp, stddev_samp\n",
    "df.select(var_pop(\"Quantity\"), var_samp(\"Quantity\"),\n",
    "  stddev_pop(\"Quantity\"), stddev_samp(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b591177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고 -> 불편분산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83c772",
   "metadata": {},
   "source": [
    "## 상관관계, 공분산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0438a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 41:>                                                         (0 + 3) / 3]\r",
      "\r",
      "[Stage 41:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|corr(InvoiceNo, Quantity)|covar_samp(InvoiceNo, Quantity)|covar_pop(InvoiceNo, Quantity)|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|     4.912186085648426E-4|              1052.728054393167|            1052.7260778770628|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr, covar_pop, covar_samp\n",
    "df.select(corr(\"InvoiceNo\", \"Quantity\"), covar_samp(\"InvoiceNo\", \"Quantity\"),\n",
    "    covar_pop(\"InvoiceNo\", \"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96b8faaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.9 MB 16.3 MB/s eta 0:00:01K     |███                             | 1.6 MB 16.3 MB/s eta 0:00:01███                   | 6.9 MB 16.3 MB/s eta 0:00:010:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.22.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88b0512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 64.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/hadoop/miniconda3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/hadoop/miniconda3/lib/python3.8/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/hadoop/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.4.2 pytz-2022.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5e2d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e122e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b005ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function var in module numpy:\n",
      "\n",
      "var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)\n",
      "    Compute the variance along the specified axis.\n",
      "    \n",
      "    Returns the variance of the array elements, a measure of the spread of a\n",
      "    distribution.  The variance is computed for the flattened array by\n",
      "    default, otherwise over the specified axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose variance is desired.  If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which the variance is computed.  The default is to\n",
      "        compute the variance of the flattened array.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If this is a tuple of ints, a variance is performed over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    dtype : data-type, optional\n",
      "        Type to use in computing the variance.  For arrays of integer type\n",
      "        the default is `float64`; for arrays of float types it is the same as\n",
      "        the array type.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  It must have\n",
      "        the same shape as the expected output, but the type is cast if\n",
      "        necessary.\n",
      "    ddof : int, optional\n",
      "        \"Delta Degrees of Freedom\": the divisor used in the calculation is\n",
      "        ``N - ddof``, where ``N`` represents the number of elements. By\n",
      "        default `ddof` is zero.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `var` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    \n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the variance. See `~numpy.ufunc.reduce` for\n",
      "        details.\n",
      "    \n",
      "        .. versionadded:: 1.20.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    variance : ndarray, see dtype parameter above\n",
      "        If ``out=None``, returns a new array containing the variance;\n",
      "        otherwise, a reference to the output array is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    std, mean, nanmean, nanstd, nanvar\n",
      "    :ref:`ufuncs-output-type`\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The variance is the average of the squared deviations from the mean,\n",
      "    i.e.,  ``var = mean(x)``, where ``x = abs(a - a.mean())**2``.\n",
      "    \n",
      "    The mean is typically calculated as ``x.sum() / N``, where ``N = len(x)``.\n",
      "    If, however, `ddof` is specified, the divisor ``N - ddof`` is used\n",
      "    instead.  In standard statistical practice, ``ddof=1`` provides an\n",
      "    unbiased estimator of the variance of a hypothetical infinite population.\n",
      "    ``ddof=0`` provides a maximum likelihood estimate of the variance for\n",
      "    normally distributed variables.\n",
      "    \n",
      "    Note that for complex numbers, the absolute value is taken before\n",
      "    squaring, so that the result is always real and nonnegative.\n",
      "    \n",
      "    For floating-point input, the variance is computed using the same\n",
      "    precision the input has.  Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for `float32` (see example\n",
      "    below).  Specifying a higher-accuracy accumulator using the ``dtype``\n",
      "    keyword can alleviate this issue.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.var(a)\n",
      "    1.25\n",
      "    >>> np.var(a, axis=0)\n",
      "    array([1.,  1.])\n",
      "    >>> np.var(a, axis=1)\n",
      "    array([0.25,  0.25])\n",
      "    \n",
      "    In single precision, var() can be inaccurate:\n",
      "    \n",
      "    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n",
      "    >>> a[0, :] = 1.0\n",
      "    >>> a[1, :] = 0.1\n",
      "    >>> np.var(a)\n",
      "    0.20250003\n",
      "    \n",
      "    Computing the variance in float64 is more accurate:\n",
      "    \n",
      "    >>> np.var(a, dtype=np.float64)\n",
      "    0.20249999932944759 # may vary\n",
      "    >>> ((1-0.55)**2 + (0.1-0.55)**2)/2\n",
      "    0.2025\n",
      "    \n",
      "    Specifying a where argument:\n",
      "    \n",
      "    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])\n",
      "    >>> np.var(a)\n",
      "    6.833333333333333 # may vary\n",
      "    >>> np.var(a, where=[[True], [True], [False]])\n",
      "    4.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.var)\n",
    "# ddof = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87259319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function var in module pandas.core.generic:\n",
      "\n",
      "var(self, axis=None, skipna=True, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      "    Return unbiased variance over requested axis.\n",
      "    \n",
      "    Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : {index (0), columns (1)}\n",
      "    skipna : bool, default True\n",
      "        Exclude NA/null values. If an entire row/column is NA, the result\n",
      "        will be NA.\n",
      "    level : int or level name, default None\n",
      "        If the axis is a MultiIndex (hierarchical), count along a\n",
      "        particular level, collapsing into a Series.\n",
      "    ddof : int, default 1\n",
      "        Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      "        where N represents the number of elements.\n",
      "    numeric_only : bool, default None\n",
      "        Include only float, int, boolean columns. If None, will attempt to use\n",
      "        everything, then use only numeric data. Not implemented for Series.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series or DataFrame (if level specified) \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      "    ...                   'age': [21, 25, 62, 43],\n",
      "    ...                   'height': [1.61, 1.87, 1.49, 2.01]}\n",
      "    ...                  ).set_index('person_id')\n",
      "    >>> df\n",
      "               age  height\n",
      "    person_id\n",
      "    0           21    1.61\n",
      "    1           25    1.87\n",
      "    2           62    1.49\n",
      "    3           43    2.01\n",
      "    \n",
      "    >>> df.var()\n",
      "    age       352.916667\n",
      "    height      0.056367\n",
      "    \n",
      "    Alternatively, ``ddof=0`` can be set to normalize by N instead of N-1:\n",
      "    \n",
      "    >>> df.var(ddof=0)\n",
      "    age       264.687500\n",
      "    height      0.042275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.var)\n",
    "# ddof = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf7b2b",
   "metadata": {},
   "source": [
    "## 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "795faf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------------+\n",
      "|InvoiceNo|quan|count(Quantity)|\n",
      "+---------+----+---------------+\n",
      "|   571906|   1|              1|\n",
      "|   572049|  20|             20|\n",
      "|   572458|  26|             26|\n",
      "|   573020|  55|             55|\n",
      "|   573256|   1|              1|\n",
      "|   573409|   1|              1|\n",
      "|   573726|   1|              1|\n",
      "|   574592|   8|              8|\n",
      "|   574844|  13|             13|\n",
      "|   574966|   8|              8|\n",
      "|   575091|  38|             38|\n",
      "|   575671|  20|             20|\n",
      "|   575948|   4|              4|\n",
      "|   575961|  13|             13|\n",
      "|   576059|  44|             44|\n",
      "|   576112|  20|             20|\n",
      "|  C576393|   2|              2|\n",
      "|   577022|  38|             38|\n",
      "|  C577362|   1|              1|\n",
      "|   577511|  46|             46|\n",
      "+---------+----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg(\n",
    "    count(\"Quantity\").alias(\"quan\"),\n",
    "    expr(\"count(Quantity)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffd70667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------------+\n",
      "|InvoiceNo|     avg(Quantity)|stddev_pop(Quantity)|\n",
      "+---------+------------------+--------------------+\n",
      "|   571906|               3.0|                 0.0|\n",
      "|   572049|              8.05|   7.559596550081228|\n",
      "|   572458|14.038461538461538|   10.04022972933147|\n",
      "|   573020| 8.272727272727273|   4.726923063991264|\n",
      "|   573256|              12.0|                 0.0|\n",
      "|   573409|               4.0|                 0.0|\n",
      "|   573726|             -67.0|                 0.0|\n",
      "|   574592|              7.25|  4.4651427748729375|\n",
      "|   574844| 6.846153846153846|   5.418574235494254|\n",
      "|   574966|               6.0|   3.640054944640259|\n",
      "|   575091|11.552631578947368|   5.008925551458656|\n",
      "|   575671|             16.65|   12.14197265686264|\n",
      "|   575948|              8.75|    8.98262211161084|\n",
      "|   575961| 2.769230769230769|  1.5268794800984005|\n",
      "|   576059|2.8181818181818183|   5.223516436936152|\n",
      "|   576112|              10.9|  7.4959989327640635|\n",
      "|  C576393|              -3.5|                 2.5|\n",
      "|   577022| 5.131578947368421|   2.903455768848916|\n",
      "|  C577362|              -2.0|                 0.0|\n",
      "|   577511|3.1739130434782608|  5.4025128928727195|\n",
      "+---------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg(expr(\"avg(Quantity)\"),expr(\"stddev_pop(Quantity)\"))\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde39fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
