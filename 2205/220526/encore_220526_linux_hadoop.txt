# 설치해야는 프로그램 
sudo yum install net-tools
sudo yum install vim -y
sudo yum install wget -y
sudo dnf install java-1.8.0-openjdk ant -y

# RedHat 보안 설정 끄기 
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=disabled/' /etc/selinux/config

# 하둡 사용자 생성 
sudo adduser hadoop
sudo passwd hadoop - 1234

# hadoop 계정 sudo 권한 주기 
sudo visudo
# 100 라인에서 아래 추가 
hadoop  ALL=(ALL)       ALL

# vim에서 default로 set number 적용하고 싶다!! 
cd ~ && vim .vimrc
set number 
# 저장하고 나오시면.... 

# hadoop으로 계정 변경
su hadoop
whoami

# hadoop 키 설정 
ssh-keygen -t rsa -> 엔터치기

# ssh 폴더로 이동 
cd ~/.ssh
cat id_rsa.pub >> authorized_keys

#권한 설정 
rw- r-- --- 해보기 ->
chmod 640 authorized_keys

# 현재 접속하고 있는 세션 
w 

# 내 컴퓨터로 다시 접속하기 
ssh localhost

# hadoop 환경파일 수정 
vim ~/.bashrc
export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el8_2.x86_64"
		/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.332.b09-2.el8_6.x86_64
source ~/.bashrc

echo $JAVA_HOME
cd /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.332.b09-2.el8_6.x86_64
pwd
ll

# hadoop 홈으로 이동
cd ~

# 하둡 다운로드 
wget https://archive.apache.org/dist/hadoop/core/hadoop-3.2.1/hadoop-3.2.1.tar.gz
# 압축 풀기
tar xvzf hadoop-3.2.1.tar.gz
# 폴더명 변경 
hadoop-3.2.1 -> hadoop 해보기 ->
mv hadoop-3.2.1 hadoop

## ssh pem 파일 만들기
cd ~/.ssh $$ cat id_rsa
다 복사
메모장에 붙여넣고 hadoop.pem으로 저장

# puttygen에서 pem파일 load하고 private 해서 ppk 만들기

# filezilla에서 ip넣고 사용자는 hadoop과 키파일 hadoop.ppk

# /home/hadoop/hadoop/etc/hadoop 이동 
# 여기에 공유폴더에 있는 파일을 복사 (D:\20220103_lab\14.python\강사님\file\hadoopfile 여기에 넣어놈)

aws에서 image만들고 그 이미지로 인스턴스 3개 생성

탄력적IP할당해줌 -> hadoop-keh-220526을 host로 쓸거임.
putty에 Logging에 Printable output체크하고 
Logfilename에서 폴더경로 지정하고 이름 &Y_&M_&D_&T.log으로 설정
Connection-Auth에 ppk 등록 Session에 ip설정해주고 save

# hosts 설정 추가 
# hosts는 dns서버보다 먼저 확인하는... 
sudo vim /etc/hosts
# 기록했던 ip 리스트를 화면의 아래에 입력
client		- 탄력적 ip 할당한 인스턴스
namenode 	- 인스턴스1 복사해서 datanode1
secondnode 	- 인스턴스2 복사해서 datanode2
datanode1
datanode2
datanode3	- 인스턴스3
적은뒤 저장!!!

# 호스트 이름 변경 
sudo hostnamectl set-hostname client

# hadoop 계정으로..
su hadoop

# 다른 컴퓨터가 살아 있는지 확인하기 
ping -c 3 namenode
ping -c 3 secondnode
ping -c 3 datanode3
	-> ping 3번으로 지정

# 다른 컴퓨터의 접속 
ssh namenode -> yes
w 해서 hadoop 나오나 보기
sudo hostnamectl set-hostname namenode

ssh secondnode
sudo hostnamectl set-hostname secondnode
ssh datanode3
sudo hostnamectl set-hostname datanode3

# /etc/hosts 파일 namenode에 /home/hadoop/hosts로 전달
scp /etc/hosts namenode:/home/hadoop/hosts
scp /etc/hosts secondnode:/home/hadoop/hosts
scp /etc/hosts datanode3:/home/hadoop/hosts

ssh namenode
# hosts파일 etc/hosts에 복사
sudo cp hosts /etc/hosts

ssh secondnode
sudo cp hosts /etc/hosts
ssh datanode3
sudo cp hosts /etc/hosts

ssh client
# bashrc 설정 
vim ~/.bashrc
export HADOOP_HOME=/home/hadoop/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$HIVE_HOME/bin
# 저장하고 나온뒤에
source ~/.bashrc
echo $HADOOP_HOME
	->/home/hadoop/hadoop 나오면 됨

# 방금 설정한 bashrc파일 3대의 컴퓨터한테 전송
scp ~/.bashrc namenode:/home/hadoop/.bashrc
scp ~/.bashrc secondnode:/home/hadoop/.bashrc
scp ~/.bashrc datanode3:/home/hadoop/.bashrc

ssh namenode
ls -al로 확인
# bashrc는 세션을 접속할때 default로 실행해서 source 안해도됨 (ssh namenocd할때 실행됨)

exit

# 원격으로 명령어 전송
ssh namenode mkdir /home/hadoop/data
ssh secondnode mkdir /home/hadoop/data
ssh datanode3 mkdir /home/hadoop/data

ssh namenode
ll 
	-> data폴더 만들어져있는지 확인

# namenode 포맷
hadoop namenode -format ( 저장공간 세팅? )

# client
start-dfs.sh
start-yarn.sh

ssh namenode
jps
# jps -> java process 확인할 때 사용하는 명령어

ssh secondnode
jps
start-yarn.sh
jps
	-> start-yarn.sh 하니까 ResourceManager 생김
stop-yarn.sh

# namenode
stop-dfs.sh
jps 
	-> jps 보면 프로세스 다 내려가있음
